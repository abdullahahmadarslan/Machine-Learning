{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ What is an N-gram Model?\n",
        "\n",
        "An **N-gram model** is a type of **language model** that predicts the next word in a sequence based on the previous \\( n - 1 \\) words.\n",
        "\n",
        "Examples:\n",
        "- **Unigram**: 1 word at a time ‚Üí \"I\", \"like\", \"pizza\"\n",
        "- **Bigram**: 2 words ‚Üí \"I like\", \"like pizza\"\n",
        "- **Trigram**: 3 words ‚Üí \"I like pizza\"\n",
        "\n",
        "It estimates:\n",
        "\\[\n",
        "P(w_n | w_{n-1}, w_{n-2}, ..., w_1) \\approx P(w_n | w_{n-1}, ..., w_{n-(n-1)})\n",
        "\\]\n",
        "\n",
        "‚úÖ So yes ‚Äî **N-gram is a basic statistical language model**.\n"
      ],
      "metadata": {
        "id": "r-8rw7voEB1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ Is it better than Bag of Words (BoW) and TF-IDF?\n",
        "\n",
        "It depends on the **task** you're working on. Here's a comparison:\n",
        "\n",
        "| Feature                | BoW                | TF-IDF             | N-gram Model         |\n",
        "|------------------------|--------------------|---------------------|----------------------|\n",
        "| Captures word order    | ‚ùå No              | ‚ùå No               | ‚úÖ Yes (context aware) |\n",
        "| Handles word importance| ‚ùå No              | ‚úÖ Yes              | ‚ùå No                 |\n",
        "| Used for               | Text classification| Same as BoW         | Language modeling, prediction |\n",
        "| Complexity             | Low                | Low                 | Higher (as n increases) |\n",
        "| Sparsity               | Sparse             | Sparse              | More sparse           |\n",
        "\n",
        "- üß† Use **BoW/TF-IDF** when classifying or clustering text.\n",
        "- üß† Use **N-gram models** when generating or predicting text.\n"
      ],
      "metadata": {
        "id": "v1upyeL7EGi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîπ Is N-gram a Language Model?\n",
        "\n",
        "‚úÖ **Yes!**\n",
        "\n",
        "An N-gram model is a **statistical language model**. It calculates the probability of word sequences.\n",
        "\n",
        "It is used for:\n",
        "- ‚úçÔ∏è Predictive typing\n",
        "- üó£Ô∏è Speech recognition\n",
        "- üåê Machine translation (older models)\n",
        "- ü§ñ Text generation\n",
        "\n",
        "While modern NLP uses deep learning (like GPT), N-grams were foundational!\n"
      ],
      "metadata": {
        "id": "2r04lYu6EOoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìò Step-by-Step Guide: Creating a Document-Term Matrix using Trigrams\n",
        "\n",
        "We are constructing a Document-Term Matrix (DTM) from a small corpus using word trigrams with specific preprocessing conditions:\n",
        "\n",
        "### üìù Given Pre-Conditions:\n",
        "- **N-gram = word**\n",
        "- **Min length of N = 3**\n",
        "- **Max length of N = 3** ‚Üí We're using **trigrams only**\n",
        "- **Stop Words Removal = True**\n",
        "- **Max Features = 4** ‚Üí We only keep the **top 4 most frequent trigrams**\n",
        "- **Term Weighting = Term Frequency** ‚Üí Values in the matrix represent how often a trigram appears in a document.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 1: Define the Corpus\n",
        "\n",
        "We start with the following four short documents:\n",
        "\n",
        "1. `\"a nice car\"`  \n",
        "2. `\"a good car\"`  \n",
        "3. `\"a beautiful car a nice car\"`  \n",
        "4. `\"a nice black car car\"`\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 2: Preprocessing (Stopword Removal + Tokenization)\n",
        "\n",
        "We remove stop words like `\"a\"`, `\"the\"`, etc., and tokenize each document into individual words.\n",
        "\n",
        "After preprocessing:\n",
        "\n",
        "1. `\"nice car\"`  \n",
        "2. `\"good car\"`  \n",
        "3. `\"beautiful car nice car\"`  \n",
        "4. `\"nice black car car\"`\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 3: Generate Trigrams (N-grams with n=3)\n",
        "\n",
        "From the preprocessed tokens, we generate **word-level trigrams** (3-word sequences).\n",
        "\n",
        "Examples:\n",
        "\n",
        "- From `\"beautiful car nice car\"` ‚Üí  \n",
        "  Trigrams = `[\"beautiful car nice\", \"car nice car\"]`\n",
        "\n",
        "- From `\"nice black car car\"` ‚Üí  \n",
        "  Trigrams = `[\"nice black car\", \"black car car\"]`\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 4: Create Vocabulary (Top 4 Features)\n",
        "\n",
        "From all trigrams, we collect their frequency and keep only the **top 4** most frequent ones:\n",
        "\n",
        "‚úÖ Selected Trigrams (Vocabulary / Columns):\n",
        "\n",
        "1. `beautiful car nice`  \n",
        "2. `black car car`  \n",
        "3. `car nice car`  \n",
        "4. `nice black car`\n",
        "\n",
        "These form the **columns** of our document-term matrix.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 5: Construct the Document-Term Matrix (DTM)\n",
        "\n",
        "We now check each document and count how many times each of the selected trigrams appears.\n",
        "\n",
        "üìå Format:  \n",
        "- **Rows** = Documents  \n",
        "- **Columns** = Trigrams (in order above)  \n",
        "- **Values** = Frequency of each trigram in the document\n",
        "\n",
        "| Document                | beautiful car nice | black car car | car nice car | nice black car |\n",
        "|-------------------------|--------------------|----------------|---------------|----------------|\n",
        "| Doc 1: \"a nice car\"      | 0                  | 0              | 0             | 0              |\n",
        "| Doc 2: \"a good car\"      | 0                  | 0              | 0             | 0              |\n",
        "| Doc 3: \"a beautiful car a nice car\" | 1         | 0              | 1             | 0              |\n",
        "| Doc 4: \"a nice black car car\"       | 0         | 1              | 0             | 1              |\n",
        "\n",
        "### üß† How This Matrix Was Built:\n",
        "\n",
        "- **Doc 1 & Doc 2**: Too short to produce any trigrams after stop word removal.  \n",
        "- **Doc 3**:\n",
        "  - `\"beautiful car nice\"` ‚Üí appears once ‚úÖ  \n",
        "  - `\"car nice car\"` ‚Üí appears once ‚úÖ  \n",
        "- **Doc 4**:\n",
        "  - `\"nice black car\"` ‚Üí appears once ‚úÖ  \n",
        "  - `\"black car car\"` ‚Üí appears once ‚úÖ\n",
        "\n",
        "This results in the frequency-based document-term matrix shown above.\n"
      ],
      "metadata": {
        "id": "DULZkvzTHwaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#CountVectorizer is a class from sklearn.feature_extraction.text that converts a collection of text documents into a matrix of token counts\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Step 2: Define the corpus (your collection of documents)\n",
        "corpus = [\n",
        "    \"a nice car\",                        # Document 1\n",
        "    \"a good car\",                        # Document 2\n",
        "    \"a beautiful car a nice car\",        # Document 3\n",
        "    \"a nice black car car\"               # Document 4\n",
        "]\n",
        "\n",
        "# Step 3: Initialize CountVectorizer with the given settings\n",
        "vectorizer = CountVectorizer(\n",
        "    stop_words='english',      # Remove common English stop words like 'a'\n",
        "    ngram_range=(3, 3),        # Use only trigrams (3-word phrases)\n",
        "    max_features=4             # Keep only the top 4 most frequent trigrams\n",
        ")\n",
        "\n",
        "# Step 4: Transform the corpus into a document-term matrix\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Step 5: Convert to a readable DataFrame using pandas\n",
        "df = pd.DataFrame(\n",
        "    data=X.toarray(),\n",
        "    index=[f\"Document {i+1}\" for i in range(len(corpus))],  # Document labels\n",
        "    columns=vectorizer.get_feature_names_out()               # Trigram features\n",
        ")\n",
        "\n",
        "# Step 6: Display the document-term matrix as a table\n",
        "print(\"üìÑ Document-Term Matrix:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnyqfr8fHVQ5",
        "outputId": "87fb23bd-fe25-4ff5-e309-f24e93f47629"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Document-Term Matrix:\n",
            "            beautiful car nice  black car car  car nice car  nice black car\n",
            "Document 1                   0              0             0               0\n",
            "Document 2                   0              0             0               0\n",
            "Document 3                   1              0             1               0\n",
            "Document 4                   0              1             0               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîß Setup: What the Code is Supposed to Do\n",
        "We are using:\n",
        "- Word-based n-grams: unigrams (1 word), bigrams (2 words), trigrams (3 words)\n",
        "- Removing English stop words\n",
        "- Keeping only the top 10 n-grams\n",
        "- Using term frequency (i.e., simple counts)\n",
        "\n",
        "üìö Step 1: Define the Corpus\n",
        "corpus = [\n",
        "    \"a nice car\",                           # Document 1\n",
        "    \"a good car\",                           # Document 2\n",
        "    \"a beautiful car a nice car\",           # Document 3\n",
        "    \"a nice black car car\"                  # Document 4\n",
        "]\n",
        "\n",
        "üßπ Step 2: Remove Stop Words\n",
        "Let‚Äôs assume \"a\" is considered a stop word.\n",
        "After stop word removal:\n",
        "\n",
        "| Document    | Cleaned Version          |\n",
        "|-------------|--------------------------|\n",
        "| Document 1  | nice car                 |\n",
        "| Document 2  | good car                 |\n",
        "| Document 3  | beautiful car nice car    |\n",
        "| Document 4  | nice black car car        |\n",
        "\n",
        "üîç Step 3: Extract N-grams (1 ‚â§ N ‚â§ 3)\n",
        "Now we extract n-grams for each document:\n",
        "\n",
        "Document 1: \"nice car\"\n",
        "- Unigrams: nice, car\n",
        "- Bigrams: nice car\n",
        "- Trigrams: (none)\n",
        "\n",
        "Document 2: \"good car\"\n",
        "- Unigrams: good, car\n",
        "- Bigrams: good car\n",
        "- Trigrams: (none)\n",
        "\n",
        "Document 3: \"beautiful car nice car\"\n",
        "- Unigrams: beautiful, car, nice\n",
        "- Bigrams: beautiful car, car nice, nice car\n",
        "- Trigrams: beautiful car nice, car nice car\n",
        "\n",
        "Document 4: \"nice black car car\"\n",
        "- Unigrams: nice, black, car\n",
        "- Bigrams: nice black, black car, car car\n",
        "- Trigrams: nice black car, black car car\n",
        "\n",
        "üìä Step 4: Count Frequencies of All N-grams\n",
        "Count across all documents:\n",
        "\n",
        "| N-gram            | Frequency |\n",
        "|-------------------|-----------|\n",
        "| car               | 4         |\n",
        "| nice              | 3         |\n",
        "| nice car          | 2         |\n",
        "| good              | 1         |\n",
        "| good car          | 1         |\n",
        "| beautiful         | 1         |\n",
        "| beautiful car     | 1         |\n",
        "| black             | 1         |\n",
        "| black car         | 1         |\n",
        "| car car           | 1         |\n",
        "| ... (others)      | ...       |\n",
        "\n",
        "Top 10 selected n-grams:\n",
        "['car', 'nice', 'nice car', 'good', 'good car',\n",
        " 'beautiful', 'beautiful car', 'black', 'black car', 'car car']\n",
        "\n",
        "üßÆ Step 5: Document-Term Matrix (DTM)\n",
        "Final 4√ó10 matrix (documents √ó top n-grams):\n",
        "\n",
        "|            | car | nice | nice car | good | good car | beautiful | beautiful car | black | black car | car car |\n",
        "|------------|-----|------|----------|------|----------|-----------|---------------|-------|-----------|---------|\n",
        "| Document 1 | 1   | 1    | 1        | 0    | 0        | 0         | 0             | 0     | 0         | 0       |\n",
        "| Document 2 | 1   | 0    | 0        | 1    | 1        | 0         | 0             | 0     | 0         | 0       |\n",
        "| Document 3 | 2   | 1    | 1        | 0    | 0        | 1         | 1             | 0     | 0         | 0       |\n",
        "| Document 4 | 2   | 1    | 0        | 0    | 0        | 0         | 0             | 1     | 1         | 1       |"
      ],
      "metadata": {
        "id": "xGVqWlfTM2UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Sample text corpus\n",
        "corpus = [\n",
        "    \"a nice car\",\n",
        "    \"a good car\",\n",
        "    \"a beautiful car a nice car\",\n",
        "    \"a nice black car car\"\n",
        "]\n",
        "\n",
        "# Initialize CountVectorizer with specified settings\n",
        "vectorizer = CountVectorizer(\n",
        "    stop_words='english',       # Remove stopwords\n",
        "    ngram_range=(1, 3),         # Include unigrams, bigrams, and trigrams\n",
        "    max_features=10             # Keep top 10 most frequent features\n",
        ")\n",
        "\n",
        "# Transform the corpus into a document-term matrix\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Convert the matrix to a pandas DataFrame\n",
        "df = pd.DataFrame(\n",
        "    data=X.toarray(),\n",
        "    index=[f\"Document {i+1}\" for i in range(len(corpus))],\n",
        "    columns=vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Display the document-term matrix\n",
        "print(\"üìÑ Document-Term Matrix:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkLuFjJwIMG3",
        "outputId": "876b5d1c-e1e2-4e73-ab21-876344a8371e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Document-Term Matrix:\n",
            "            beautiful  beautiful car  beautiful car nice  black  black car  \\\n",
            "Document 1          0              0                   0      0          0   \n",
            "Document 2          0              0                   0      0          0   \n",
            "Document 3          1              1                   1      0          0   \n",
            "Document 4          0              0                   0      1          1   \n",
            "\n",
            "            black car car  car  car car  nice  nice car  \n",
            "Document 1              0    1        0     1         1  \n",
            "Document 2              0    1        0     0         0  \n",
            "Document 3              0    2        0     1         1  \n",
            "Document 4              1    2        1     1         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "el7xrWwOLXvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}